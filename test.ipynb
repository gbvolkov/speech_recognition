{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "from main import find_intersections\n",
    "\n",
    "#pipeline = Pipeline.from_pretrained(\n",
    "#    \"pyannote/speaker-diarization-3.1\",\n",
    "#    use_auth_token=\"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\")\n",
    "TOKEN=\"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\"\n",
    "AUDIO=\"audio/2407151757656693.1.0.0.mp3\"\n",
    "WHISPER_MODEL=\"medium\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=2.9s stop=4.0s speaker_SPEAKER_02\n",
      "start=11.8s stop=25.0s speaker_SPEAKER_00\n",
      "start=25.4s stop=28.3s speaker_SPEAKER_00\n",
      "start=29.3s stop=29.6s speaker_SPEAKER_02\n",
      "start=32.1s stop=37.6s speaker_SPEAKER_00\n",
      "start=38.8s stop=39.1s speaker_SPEAKER_01\n",
      "start=40.6s stop=43.4s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"/Users/7810155/Documents/Projects/AI/models/speaker-diarization-3.1/config.yaml\",\n",
    "    use_auth_token=TOKEN)\n",
    "\n",
    "# send pipeline to GPU (when available)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipeline.to(torch.device(DEVICE))\n",
    "\n",
    "waveform, sample_rate = torchaudio.load(AUDIO)\n",
    "diarization = pipeline({\"waveform\": waveform, \"sample_rate\": sample_rate})\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0s - 1.0s:  Здравствуйте.\n",
      "1.0s - 15.6s:  ООВ интерлизинг уведомляет вас о просроченной задолженности\n",
      "15.6s - 18.5s:  в размере в 100 000 рублей по лизинговому договору,\n",
      "18.5s - 21.0s:  заключенному слову AdarStroy, предмет лизинга рифковой\n",
      "21.0s - 22.7s:  автомобиль Lada XRi.\n",
      "22.7s - 25.4s:  Просим вас незамедлительно произвести оплату.\n",
      "25.4s - 28.0s:  Если вы уже оплатили просроченную задолженность, скажите\n",
      "28.1s - 29.1s:  да.\n",
      "29.1s - 30.1s:  Нет.\n",
      "30.1s - 35.2s:  Если у вас остались вопросы или вам необходима консультация\n",
      "35.2s - 38.8s:  специалиста, скажите да или нет.\n",
      "38.8s - 39.8s:  Да.\n",
      "39.8s - 42.7s:  С уважением к вам и к вашему бизнесу.\n",
      "42.7s - 43.4s:  Интерлизинг.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(WHISPER_MODEL)\n",
    "script = model.transcribe(AUDIO)\n",
    "\n",
    "for segment in script[\"segments\"]:\n",
    "    print(f\"{segment['start']:.1f}s - {segment['end']:.1f}s: {segment['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersections2(speakers, texts):\n",
    "    intersections = []\n",
    "\n",
    "    for text in texts:\n",
    "        text_start, text_end = text['start'], text['end']-0.1\n",
    "        for turn, _, speaker in speakers.itertracks(yield_label=True):\n",
    "            speaker_start, speaker_end = turn.start, turn.end\n",
    "            \n",
    "            # Find the overlap between the speaker's interval and the text's interval\n",
    "            start = max(text_start, speaker_start)\n",
    "            end = min(text_end, speaker_end)\n",
    "            \n",
    "            if start < end:  # There is an intersection\n",
    "                if intersections and intersections[-1]['speaker'] == speaker:\n",
    "                    intersections[-1]['end'] = end\n",
    "                    intersections[-1]['text'] += ' ' + text['text']\n",
    "                else:\n",
    "                    intersections.append({\n",
    "                        'start': start,\n",
    "                        'end': end,\n",
    "                        'speaker': speaker,\n",
    "                        'text': text['text']\n",
    "                    })\n",
    "    return intersections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9s - 4.0s: SPEAKER_02:  ООВ интерлизинг уведомляет вас о просроченной задолженности\n",
      "11.8s - 28.3s: SPEAKER_00:  ООВ интерлизинг уведомляет вас о просроченной задолженности  в размере в 100 000 рублей по лизинговому договору,  заключенному слову AdarStroy, предмет лизинга рифковой  автомобиль Lada XRi.  Просим вас незамедлительно произвести оплату.  Если вы уже оплатили просроченную задолженность, скажите  да.\n",
      "29.3s - 29.6s: SPEAKER_02:  Нет.\n",
      "32.1s - 37.6s: SPEAKER_00:  Если у вас остались вопросы или вам необходима консультация  специалиста, скажите да или нет.\n",
      "38.8s - 39.1s: SPEAKER_01:  Да.\n",
      "40.6s - 43.3s: SPEAKER_00:  С уважением к вам и к вашему бизнесу.  Интерлизинг.\n"
     ]
    }
   ],
   "source": [
    "intersections = find_intersections2(diarization, script[\"segments\"])\n",
    "for segment in intersections[0:]:\n",
    "    print(f\"{segment['start']:.1f}s - {segment['end']:.1f}s: {segment['speaker']}: {segment['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Segment.overlaps of <Segment(2.89474, 4.01528)>>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x1, x2, x3 in diarization.itertracks(yield_label=True):\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
